{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fce02f37aa4ed0f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Invariant Mass Prediction Using ML\n",
    "## Bryan Dinh\n",
    "### Comp_Phys Final Project 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898b50cd0e98a9b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Model Goal: Predict the invariant mass of a particle decay process which results in the creation of two muons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9aee7fa55da6fc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T18:44:57.356226900Z",
     "start_time": "2023-11-22T18:44:57.334928500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9900734b8ae4d3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T18:44:57.801864Z",
     "start_time": "2023-11-22T18:44:57.798756Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfe95f1f958dd4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baa313c260f2b842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:37:30.988770800Z",
     "start_time": "2023-11-21T22:37:30.693930900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\PycharmProjects\\comp_phys_2023\\Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pair Mass</th>\n",
       "      <th>Muon 1 Energy</th>\n",
       "      <th>Muon 2 Energy</th>\n",
       "      <th>Muon 1 pT</th>\n",
       "      <th>Muon 2 pT</th>\n",
       "      <th>Muon 1 Eta</th>\n",
       "      <th>Muon 2 Eta</th>\n",
       "      <th>Muon 1 Phi</th>\n",
       "      <th>Muon 2 Phi</th>\n",
       "      <th>Muon 1 Rapidity</th>\n",
       "      <th>Muon 2 Rapidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>4.19125</td>\n",
       "      <td>5.06381</td>\n",
       "      <td>7.09718</td>\n",
       "      <td>4.57564</td>\n",
       "      <td>3.71216</td>\n",
       "      <td>0.457408</td>\n",
       "      <td>1.264380</td>\n",
       "      <td>3.039380</td>\n",
       "      <td>2.447480</td>\n",
       "      <td>0.457294</td>\n",
       "      <td>1.264040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>8.59466</td>\n",
       "      <td>5.27870</td>\n",
       "      <td>7.09718</td>\n",
       "      <td>4.45581</td>\n",
       "      <td>3.71216</td>\n",
       "      <td>0.598385</td>\n",
       "      <td>1.264380</td>\n",
       "      <td>-0.631795</td>\n",
       "      <td>2.447480</td>\n",
       "      <td>0.598235</td>\n",
       "      <td>1.264040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>22.63070</td>\n",
       "      <td>8.01042</td>\n",
       "      <td>27.69420</td>\n",
       "      <td>7.59714</td>\n",
       "      <td>5.36723</td>\n",
       "      <td>-0.328096</td>\n",
       "      <td>2.324520</td>\n",
       "      <td>-2.621600</td>\n",
       "      <td>-0.978774</td>\n",
       "      <td>-0.328065</td>\n",
       "      <td>2.324330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>12.34510</td>\n",
       "      <td>8.01042</td>\n",
       "      <td>5.55988</td>\n",
       "      <td>7.59714</td>\n",
       "      <td>5.32962</td>\n",
       "      <td>-0.328096</td>\n",
       "      <td>-0.292268</td>\n",
       "      <td>-2.621600</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>-0.328065</td>\n",
       "      <td>-0.292212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>9.41510</td>\n",
       "      <td>8.01042</td>\n",
       "      <td>3.98217</td>\n",
       "      <td>7.59714</td>\n",
       "      <td>3.74132</td>\n",
       "      <td>-0.328096</td>\n",
       "      <td>-0.355897</td>\n",
       "      <td>-2.621600</td>\n",
       "      <td>1.475980</td>\n",
       "      <td>-0.328065</td>\n",
       "      <td>-0.355761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pair Mass  Muon 1 Energy  Muon 2 Energy  Muon 1 pT  Muon 2 pT  \\\n",
       "25000    4.19125        5.06381        7.09718    4.57564    3.71216   \n",
       "25001    8.59466        5.27870        7.09718    4.45581    3.71216   \n",
       "25002   22.63070        8.01042       27.69420    7.59714    5.36723   \n",
       "25003   12.34510        8.01042        5.55988    7.59714    5.32962   \n",
       "25004    9.41510        8.01042        3.98217    7.59714    3.74132   \n",
       "\n",
       "       Muon 1 Eta  Muon 2 Eta  Muon 1 Phi  Muon 2 Phi  Muon 1 Rapidity  \\\n",
       "25000    0.457408    1.264380    3.039380    2.447480         0.457294   \n",
       "25001    0.598385    1.264380   -0.631795    2.447480         0.598235   \n",
       "25002   -0.328096    2.324520   -2.621600   -0.978774        -0.328065   \n",
       "25003   -0.328096   -0.292268   -2.621600    0.039000        -0.328065   \n",
       "25004   -0.328096   -0.355897   -2.621600    1.475980        -0.328065   \n",
       "\n",
       "       Muon 2 Rapidity  \n",
       "25000         1.264040  \n",
       "25001         1.264040  \n",
       "25002         2.324330  \n",
       "25003        -0.292212  \n",
       "25004        -0.355761  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir(os.path.dirname(BD_ML_Training.ipynb))\n",
    "#os.chdir('../') # Get out of current folder\n",
    "\n",
    "os.chdir(os.path.abspath(\"C:\\\\Users\\\\Bryan\\\\PycharmProjects\\\\comp_phys_2023\\\\Data\")) # Dont hardcode\n",
    "cwd=os.getcwd()\n",
    "print(cwd)\n",
    "train2=pd.read_csv(cwd+\"\\\\trainDataset2.csv\",index_col=0)\n",
    "test=pd.read_csv(cwd+\"\\\\FinalDataset.csv\",index_col=0)\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c74b8dbc0409c6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Normalizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e0d9368c143748",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:37:38.266064400Z",
     "start_time": "2023-11-21T22:37:37.663258300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate Target and Predictor Variables\n",
    "TargetVariable=['Pair Mass']\n",
    "Predictors=['Pair Mass','Muon 1 Energy','Muon 2 Energy',\n",
    "            'Muon 1 pT','Muon 2 pT','Muon 1 Eta','Muon 2 Eta','Muon 1 Phi','Muon 2 Phi','Muon 1 Rapidity','Muon 2 Rapidity']\n",
    "\n",
    "X=train2[Predictors].values\n",
    "Y=train2[TargetVariable].values\n",
    "\n",
    "X_test=test[Predictors].values\n",
    "Y_test=test[TargetVariable].values\n",
    "### Standardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "PredictorScaler=StandardScaler()\n",
    "TargetVarScaler=StandardScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "TargetVarScalerFit=TargetVarScaler.fit(Y)\n",
    "\n",
    "\n",
    "# Generating the standardized values of X and y\n",
    "X=PredictorScalerFit.transform(X)\n",
    "Y=TargetVarScalerFit.transform(Y)\n",
    "X=PredictorScalerFit.transform(X_test)\n",
    "Y=TargetVarScalerFit.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ec9b14ec22a432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T22:46:33.757943Z",
     "start_time": "2023-11-21T22:37:40.489226100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6949/6949 [==============================] - 11s 1ms/step - loss: 0.1099\n",
      "Epoch 2/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0260\n",
      "Epoch 3/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0141\n",
      "Epoch 4/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0091\n",
      "Epoch 5/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0065\n",
      "Epoch 6/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0049\n",
      "Epoch 7/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0037\n",
      "Epoch 8/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0032\n",
      "Epoch 9/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0026\n",
      "Epoch 10/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0024\n",
      "Epoch 11/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0020\n",
      "Epoch 12/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0019\n",
      "Epoch 13/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0017\n",
      "Epoch 14/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0018\n",
      "Epoch 15/50\n",
      "6949/6949 [==============================] - 8s 1ms/step - loss: 0.0020\n",
      "Epoch 16/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0015\n",
      "Epoch 17/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0014\n",
      "Epoch 18/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0013\n",
      "Epoch 19/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 0.0013\n",
      "Epoch 20/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 0.0014\n",
      "Epoch 21/50\n",
      "6949/6949 [==============================] - 9s 1ms/step - loss: 0.0014\n",
      "Epoch 22/50\n",
      "6949/6949 [==============================] - 15s 2ms/step - loss: 0.0013\n",
      "Epoch 23/50\n",
      "6949/6949 [==============================] - 14s 2ms/step - loss: 0.0011\n",
      "Epoch 24/50\n",
      "6949/6949 [==============================] - 14s 2ms/step - loss: 0.0015\n",
      "Epoch 25/50\n",
      "6949/6949 [==============================] - 13s 2ms/step - loss: 0.0012\n",
      "Epoch 26/50\n",
      "6949/6949 [==============================] - 14s 2ms/step - loss: 9.4083e-04\n",
      "Epoch 27/50\n",
      "6949/6949 [==============================] - 14s 2ms/step - loss: 0.0010\n",
      "Epoch 28/50\n",
      "6949/6949 [==============================] - 13s 2ms/step - loss: 8.8952e-04\n",
      "Epoch 29/50\n",
      "6949/6949 [==============================] - 13s 2ms/step - loss: 8.2196e-04\n",
      "Epoch 30/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 6.9224e-04\n",
      "Epoch 31/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 7.1200e-04\n",
      "Epoch 32/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 6.6279e-04\n",
      "Epoch 33/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 7.7615e-04\n",
      "Epoch 34/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 4.8377e-04\n",
      "Epoch 35/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 6.7196e-04\n",
      "Epoch 36/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 4.6376e-04\n",
      "Epoch 37/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 4.8296e-04\n",
      "Epoch 38/50\n",
      "6949/6949 [==============================] - 10s 2ms/step - loss: 4.2774e-04\n",
      "Epoch 39/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 4.1180e-04\n",
      "Epoch 40/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 6.3356e-04\n",
      "Epoch 41/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 4.8814e-04\n",
      "Epoch 42/50\n",
      "6949/6949 [==============================] - 10s 2ms/step - loss: 3.4071e-04\n",
      "Epoch 43/50\n",
      "6949/6949 [==============================] - 10s 2ms/step - loss: 4.5011e-04\n",
      "Epoch 44/50\n",
      "6949/6949 [==============================] - 10s 2ms/step - loss: 3.2434e-04\n",
      "Epoch 45/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 8.2156e-04\n",
      "Epoch 46/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 3.5334e-04\n",
      "Epoch 47/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 4.5699e-04\n",
      "Epoch 48/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 6.2015e-04\n",
      "Epoch 49/50\n",
      "6949/6949 [==============================] - 10s 1ms/step - loss: 3.7390e-04\n",
      "Epoch 50/50\n",
      "6949/6949 [==============================] - 11s 2ms/step - loss: 5.1315e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2980f2f6c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Create ANN Model\n",
    "model=Sequential()\n",
    "\n",
    "# Defining the Input layer and FIRST hidden layer, both are same!\n",
    "model.add(Dense(units=5, input_dim=11, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "# Defining the Second layer of the model\n",
    "# after the first layer we don't have to specify input_dim as keras configure it automatically\n",
    "model.add(Dense(units=5, kernel_initializer='normal', activation='tanh'))\n",
    "\n",
    "# The output neuron is a single fully connected node \n",
    "# Since we will be predicting a single number\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "          \n",
    "# Compiling the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X, Y ,batch_size = 20, epochs = 50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13f36ddeb313811f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T18:22:10.951113100Z",
     "start_time": "2023-11-22T18:20:46.131666200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchResultsData\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Calling the function\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m ResultsData \u001b[38;5;241m=\u001b[39m FunctionFindBestParams(X, Y, X_test, Y_test)\n",
      "Cell \u001b[1;32mIn[14], line 32\u001b[0m, in \u001b[0;36mFunctionFindBestParams\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Fitting the ANN to the Training set\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size_trial, epochs\u001b[38;5;241m=\u001b[39mepochs_trial, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     34\u001b[0m MAPE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (np\u001b[38;5;241m.\u001b[39mabs(y_test \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)) \u001b[38;5;241m/\u001b[39m y_test))\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# printing the results of the current iteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\keras\\src\\engine\\training.py:1733\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1731\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1733\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1734\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m         ):\n\u001b[0;32m   1741\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1401\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1400\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1401\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1402\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1403\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1405\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1406\u001b[0m )\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:688\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    687\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    689\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    690\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:815\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \n\u001b[0;32m    808\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 815\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:794\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    792\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 794\u001b[0m   result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    797\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    798\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    800\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    801\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    802\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:784\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    783\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 784\u001b[0m result \u001b[38;5;241m=\u001b[39m gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mread_variable_op(\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n\u001b[0;32m    786\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\comp_phys\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:581\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    580\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m    582\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, resource, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype)\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    584\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining a function to find the best parameters for ANN\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyperparameters to try\n",
    "    batch_size_list = [15, 20]\n",
    "    epoch_list = [20, 40]\n",
    "    \n",
    "    import pandas as pd\n",
    "    SearchResultsDataList = []  # List to store data frames\n",
    "    \n",
    "    # Initializing the trials\n",
    "    TrialNumber = 0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber += 1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train, batch_size=batch_size_trial, epochs=epochs_trial, verbose=0)\n",
    "\n",
    "            MAPE = np.mean(100 * (np.abs(y_test - model.predict(X_test)) / y_test))\n",
    "            \n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:', 'batch_size:', batch_size_trial, '-', 'epochs:', epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "            \n",
    "            # Append the current iteration's results to the list\n",
    "            SearchResultsDataList.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], columns=['TrialNumber', 'Parameters', 'Accuracy']))\n",
    "\n",
    "    # Concatenate all the data frames in the list\n",
    "    SearchResultsData = pd.concat(SearchResultsDataList, ignore_index=True)\n",
    "    \n",
    "    return SearchResultsData\n",
    "\n",
    "# Calling the function\n",
    "ResultsData = FunctionFindBestParams(X, Y, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa90441c255c11",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2db2bf888da0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce4210338bb95a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4896c0b5949ec5d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Defining a function to find the best parameters for ANN\n",
    "def FunctionFindBestParams(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Defining the list of hyper parameters to try\n",
    "    batch_size_list=[5, 10, 15, 20]\n",
    "    epoch_list  =   [5, 10, 50, 100]\n",
    "    \n",
    "    import pandas as pd\n",
    "    SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
    "    \n",
    "    # initializing the trials\n",
    "    TrialNumber=0\n",
    "    for batch_size_trial in batch_size_list:\n",
    "        for epochs_trial in epoch_list:\n",
    "            TrialNumber+=1\n",
    "            # create ANN model\n",
    "            model = Sequential()\n",
    "            # Defining the first layer of the model\n",
    "            model.add(Dense(units=5, input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # Defining the Second layer of the model\n",
    "            model.add(Dense(units=5, kernel_initializer='normal', activation='relu'))\n",
    "\n",
    "            # The output neuron is a single fully connected node \n",
    "            # Since we will be predicting a single number\n",
    "            model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "            # Compiling the model\n",
    "            model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "            # Fitting the ANN to the Training set\n",
    "            model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
    "\n",
    "            MAPE = np.mean(100 * (np.abs(y_test-model.predict(X_test))/y_test))\n",
    "            \n",
    "            # printing the results of the current iteration\n",
    "            print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
    "            SearchResultsData = SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], columns=['TrialNumber', 'Parameters', 'Accuracy']), ignore_index=True)\n",
    "\n",
    "            #SearchResultsData=SearchResultsData(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]], columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
    "    return(SearchResultsData)\n",
    "\n",
    "\n",
    "######################################################\n",
    "# Calling the function\n",
    "ResultsData=FunctionFindBestParams(X, Y, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1c9d1056bc35c8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T22:15:12.724999400Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da95446e4e732",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T22:15:12.726993600Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
